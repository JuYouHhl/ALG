# 自我介绍
面试官您好，我是胡红利，来自湖北十堰，2019年就读于长安大学计算机科学与技术专业，2023年攻读硕士学位，目前研二。
研究生阶段，我专注于计算机视觉与深度学习领域，深入学习了目标检测与位姿估计等视觉算法及相关检测框架，同时，我学习了扩散模型及大模型的相关知识，并且参与了基于扩散模型的目标检测与位姿估计、文本模态视觉检测等项目。
目前一篇EI会议已发表，一篇ccf-a会议在投，一篇ccf-b会议在返修，一篇中文ccf-a期刊外审。在校期间多次参加国家级大赛并获得两项国家级、一项省级等奖项。以上是我的自我介绍，感谢您的聆听，您有需要问的我会认真回答。

# 项目

##  基于单幅RGB图像的单、多目标三维视觉定位方法

鉴于三维视觉定位领域中主流数据集是基于室内场景的且基于单目标，而基于雷达采集架构部署成本高普适性差的问题，我们提出了一个基于RGB图像的单、多目标的三维视觉定位基准数据集，有效地弥补了基于单眼图像的3DVG的研究空白。此外这项工作提出了首个端到端基于单目图像的3DVG框架，旨在有效增强多尺度特征地图的语义引导感知。

U2ENet包括三个主要组件：多模态特征提取器，多尺度语义感知分层融合模块以及grounding head。在多模态特征提取器中，使用预训练的 roberta-based 模型提取文本表示序列，使用预训练的深度聚合网络 DLA34 视觉主干提取多尺度特征图。利用 Mamba2 的过滤掉不相关的特征，保留重要的文本序列。随后将文本特征与视觉特征作为状态空间模型的输入，使得输出能够同时保留语义与视觉特征。经过三次迭代，将得到的分层语义表示用作语义指导，增强多尺度特征图的语义感知，最后通过多任务头预测满足语义要求的三维检测结果。

**1) 多模态特征提取器**

**深度聚合网络**

语义融合：在通道方向进行的聚合，能够提高模型推断“是什么”的能力（what）
空间融合：在分辨率和尺度方向的融合，能够提高模型推断“在哪里”的能力（where）

DenseNets 是语义融合的代表，通过跳跃连接所有的层来获得更好的聚合特征和误差。FPNs 是空间融合的代表，通过自上而下和侧边连接来补偿分辨率和标准化金字塔型的层级特征语义。**DLA 则将两者更好地结合起来。**

DLA 核心模块：迭代式深度聚合 IDA 和层级深度聚合 HDA。IDA主要进行跨分辨率和尺度的融合，而HDA主要用于融合各个 module 和 channel 的特征。DA沿着迭代堆叠的backbone进行，依据分辨率对整个网络分stage，越深的stage含有更多的语义信息但空间信息很少。IDA结构，从最浅最小的尺度开始，迭代式地融合更深更大尺度地信息，这样可以使得浅层网络信息在后续stage中获得更多地处理从而得到精炼。尽管IDA可以高效组合stage，但它依然是序列性的，不足以用来融合网络各个block信息。HDA以树的形式合并block和stage来保持和组合特征通道，通过HDA，浅层和深层的网络层可以组合到一起，这样的组合信息可以跨越各个层级从而学得更加丰富。

“聚合”定义为跨越整个网络的多层组合，文中研究的也是那些深度、分辨率、尺度上能有效聚合的一系列网络。由于网络可以包含许多层和连接，模块化的设计可以通过分组和重复来克服复杂度问题。多个layer组合为一个block，多个block再根据分辨率组合为一个stage，DLA则主要探讨block和stage的组合（stage间网络保持一致分辨率，那么空间融合发生在stage间，语义融合发生在stage内）。

**2) 语义感知与融合**

使用roberta-based 模型提取文本表示序列得到浅层次的语义特征，使用三个堆叠的SSD模块递归处理这些语义特征来获得多层次的上下文语义表示并基于选择性机制对无关信息进行过滤，对主干提取到的多尺度特征图进行特征融合，在SSM 模块中，矩阵 B 和步长(∆)从文本嵌入获得，矩阵 C 从视觉嵌入得到，将视觉信息嵌入到状态表示中，最终的输出能够同时捕获视觉特征与语义特征。

**Transformer的问题**：

Transformer 结构的核心在于自注意力机制，它在处理序列数据时，首先通过位置编码将数据空间化，并在有限窗口内计算序列元素之间的关联。然而，这种机制有一个显著的局限性，即它的计算范围仅限于窗口内，无法直接处理窗口外的元素，导致视野狭窄，信息孤立，缺乏全局建模能力。

虽然理论上可以通过增加窗口长度来扩展模型的视野，但这会导致计算复杂度呈平方增长 O(n2)，因为每个位置需要与窗口内的所有其他位置进行比较。此外，Transformer 通过计算空间相关度来建模时序相关度，这种方式忽略了数据内在的细腻结构关联，导致参数效率低，冗余高，训练不易。

这种局限源于当初为了利用 GPU 并行能力而选择的空间化处理方法，而非最佳的时序建模方式。因此，长序列建模逐渐回归传统方法，特别是时序状态空间模型 (SSM)，而其中的 Mamba 模型在这一领域表现出色。

**状态空间模型 (State Space Model)**：

SSM 是一种描述动态系统行为的数学模型，它使用一组一阶微分方程（连续时间系统）或差分方程（离散时间系统）来表示系统的内部状态的演化，同时用另一组方程来描述系统状态和输出之间的关系。其基本形式通过以下状态方程和输出方程表示：

状态方程： $h'(t)=Ah(t)+Bx(t)$
输出方程： $y(t)=Ch'(t)$

SSM 将一个输入向量 $x(t)$ 映射为一个潜在状态变量 $h'(t)$，，然后再映射为一个输出向量 $y(t)$。通过输入信号与隐状态的关系来建模系统的动态行为，并且能够应对时变和非线性系统，因而具有很强的通用性。SSM 模型的核心优势在于其对时序关系的建模和在动态系统中的应用。

**SSM->S4D**

1）**离散数据的连续化：基于零阶保持技术做连续化并采样**。利用零阶保持技术处理离散的输入(如文本序列)。每次收到离散信号时，都会保留其值直到收到新的离散信号，使得 SSM 可以使用连续信号，保持该值的时间由一个新的可学习参数表示，称为步长(∆)。有了连续的输入信号后，便可以生成连续的输出，并且仅根据输入的时间步长对值进行采样。这些采样值即离散输出。最终能够从连续 SSM 转变为离散SSM，使得不再是函数到函数，而是序列到序列。

2）**卷积结构表示：方便并行训练**。图像识别任务中，使用过滤器(即卷积核kernels)来导出聚合特征，而SSM也可以表示成卷积的形式，使用一维卷积核。将 SSM 表示为卷积的一个主要好处是它可以像卷积神经网络CNN一样进行并行训练。然而，由于内核大小固定，它们的推理不如 RNN 那样快速。解决办法：作为从输入信号到输出信号的参数化映射，SSMs可以当做是RNN与CNN的结合，即推理用RNN结构，训练用CNN结构。

3）**长距离依赖问题的解决：HiPPO**。HiPPO 矩阵通常用于将连续时间信号投影到正交多项式基下，以代表过去的状态/信息，尝试将当前看到的所有输入信号压缩为一个系数向量，通过函数逼近产生状态矩阵 A 的最优解。使得在被应用于循环表示和卷积表示中时，可以处理远程依赖性。

4）**S4 与 S4D**。S4：综合SSM + 离散化(可循环表示或卷积表示) + HiPPO 。S4D：将参数矩阵标准化为对角结构。

S4模型使用四个参数（$\Delta A$, $B$, $C$）定义序列到序列的转换过程，分为两个阶段：第一阶段（离散化）：将“连续参数”（$\Delta A$, $B$）转换为“离散参数”（$\bar{A}$, $\bar{B}$）。第二阶段：通过离散化后的参数计算序列转换，可以通过线性递归或全局卷积两种方式实现。

$h_t = \bar{A} h_{t-1} + \bar{B} x_t$

$A$是状态转换矩阵，$B$是输入到状态的转换矩阵，$x(t)$是当前时间步的输入。这表明当前的潜在状态$h(t)$是由前一个时间步的潜在状态$h_{t-1}$和当前输入的组合递归决定决定的。

$y_t = C h_t$

$C$是状态到输出的转换矩阵。输出直接依赖于当前的潜在状态。输出$y_t$是当前潜在状态$h_t$的直接函数。



**Mamba = 有选择处理信息 + 硬件感知算法 + 更简单的SSM架构**

- **选择性状态空间模型**：SSM 中的矩阵A B C不随输入不同而不同，即无法针对不同的输入针对性的推理。Mamba的解决办法是，相比SSM压缩所有历史记录，mamba设计了一个简单的选择机制，通过“参数化SSM的输入”，让模型对信息有选择性处理，以便关注或忽略特定的输入。
- **硬件感知的设计**：并行扫描(parallel scan)且借鉴Flash Attention。无法使用卷积表示来计算 A B C这些动态矩阵(CNN需要固定的内核)，
- **简化的SSM架构**：将大多数SSM架构的基础块，与现代神经网络比如Transformer中普遍存在的Gated MLP相结合，组成新的Mamba块，然后重复这个块(且与归一化和残差连接结合)，便构成了Mamba架构






## 基于扩散模型的目标检测与位姿估计算法
研究路侧交通场景下仅以单目RGB图像为输入的基于扩散模型的目标检测与位姿估计算法设计与应用，将目标检测与位姿估计转换为图像中边界框的位置和大小空间上的生成模型来解决问题，训练阶段将真值框扩散到随机分布，通过训练模型来逐渐逆转正向过程的影响，模型学习反转这个噪声过程，将一组随机生成的框细化到类别、目标框及位姿的输出结果。

**网络结构**

网络由一个图像编码器和一个多任务解码器组成。图像编码器使用 resnet 提取图像特征，并使用特征图金字塔FPN生成多尺度特征图。多任务解码器的输入为加入噪声后的二维框，从多尺度特征图中裁剪RoI特征，并经过MLP输出目标检测与位姿估计的预测结果。
训练阶段初始化一组2dbox，并逐步加入高斯噪声，得到噪声2dbox，并从图像编码器提取到的特征裁剪出感兴趣区域，将裁剪得到的特征送入到解码器中预测真值并计算loss。
再推理时，生成一组完全由高斯噪声生成的噪声2dbox，接着同样的步骤得到解码器预测的2dbox(xt)，采用ddim传入当前的噪声样本 xt 与预测的目标框 x0，预测上一时刻 xt-1 的数据分布，反复迭代直至0时刻。

**DDIM**

DDIM 通过重新设计前向过程，允许非马尔可夫链的跳跃路径，从而减少反向过程的迭代步数。
假设扩散过程的时间步总数为 T，在前向过程中，直接定义从初始状态 x0 到任意时间步 t 的映射：
$$\mathbf{x}_t = \sqrt{\bar{\alpha}}_t \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}}_t \mathbf{\epsilon}, \quad \mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$

其中，$\bar{\alpha}_t$ 是累积噪声调度参数（与 DDPM 相同）。

在反向过程中，通过预测初始状态 x0 和当前噪声 ${\epsilon}_{t}$ ，直接跳步生成下一步状态xt-1。

**DETR**

DETR 分为四个部分，CNN 的 backbone，Transformer 的 Encoder与Decoder，及预测层 FFN。在Decoder中选择固定的 N 个 token 作为输入，并行解码 N 个object，经过FFN 就能得到 N 个框的位置和类别分数。FFN 是由具有 ReLU 激活函数且具有隐藏层的 3 层线性层组成。DETR 预测了一组固定大小的 N 个边界框，因此将真值也扩展为N个并采用匈牙利算法进行二分图匹配，使得匹配损失最小。

**Sparse rcnn**

由基于ResNet结构的特征金字塔网络的主干网络、一个动态实例交互头和两个任务特定的预测层组成。一共有3个输入：一幅图像、一个建议边界框集合和一个建议特征集合。后两者是可学习的，可以与网络中的其它参数一起优化。可学习的建议边界框是一个固定的（N×4）集合，提供粗糙的目标位置。可学习的建议特征（N×d）是一个高维的潜在向量，被期望于对丰富的实例特征进行编码。 给定 N 个建议边界框，Sparse R-CNN首先利用池化操作为每个边界框提取特征，每个RoI特征被输入动态实例交互头进行目标定位和分类。头是一组可迭代的同样结构的交互头，上一个head的输出特征与2dboxes作为下一个头的输入特征和2dboxes。

## 基于轨迹时空图的无监督异常检测方法
基于工业领域无监督异常检测方法EfficientAD进行改进。EfficientAD由一个学生教师对和一个自编码器组成，自动编码器检测逻辑异常(产品的组装错误...)，而学生-教师模型检测粗粒度和细粒度的结构异常(产品物理缺陷...)。异常图是两个输出之间的平方差。将学生-教师对生成的异常图称为局部异常图，学生-自编码器生成的异常图称为全局异常图，取这两个异常图的均值来计算合并的异常图，并将其最大值作为图像级异常评分。使用注意力模块替换自编码器，在使用线性注意力模块时，取得了最佳性能。

**PDN(TS架构)**

特征提取器仅由四个卷积层组成，以完全卷积方式将其应用于图像可以在一次前向传递中产生所有特征。为了使 PDN 生成富有表现力的特征，将深度预训练分类网络提炼到其中。使用与 WideResNet-101中的 PatchCore相同的预训练特征。通过最小化PDN输出与从预训练网络中提取的特征之间的均方差来训练来自 ImageNet的图像。
训练学生网络来预测教师网络（教师网络经过预训练）在正常（即无异常）训练图像上计算的特征。由于学生网络没有接受过异常图像方面的训练，因此通常无法在这些方面模仿教师网络。因此，教师和学生的输出之间存在较大距离，因此可以在测试时检测到异常情况。

**自编码器**

使用标准的卷积自编码器，包括编码器中的跨步卷积和解码器中的双线性上采样。学生学习自动编码器在正常图像上的系统重建误差，例如模糊重建。同时，它不会学习异常的重建错误，因为这些不是训练集的一部分。这使得自动编码器的输出和学生的输出之间的差异非常 适合计算异常图。

**异常图标准化**

局部和全局异常图必须先标准化为相似的比例，然后再对其进行平均以获得组合异常图。为了估计正常图像中噪声的规模，使用验证图像，即训练集中未见过的图像。对于每一种异常图类型，计算验证图像上所有像素异常分数的集合。然后，为每个集合计算两个 p-分位数：pa 和 pb ，分别表示 p = a 和 p = b。我们确定一个线性变换，将 pa 映射到异 常分数 0，将 pb 映射到分数 0.1。在测试时，局部和全局异常图通过各自的线性变换进 行归一化。通过使用分位数，归一化对于正常图像上的异常分数的分布变得鲁棒。

**Linear Attention**

注意力机制通过计算查询向量与所有键向量的相似度，获得注意力权重，再用这些权重对相应的值向量进行加权组合。在此过程中使用softmax函数的目的是将原始相似度分数转换为概率分布，线性注意力将softmax指数函数重写为特征映射函数φ(x)=elu(x) + 1的点积形式的核函数，利用矩阵乘法的结合律，将注意力计算重构为线性形式。这种重构方法消除了计算完整N×N注意力矩阵的需求，将复杂度降低至O(Nd²)，其中d表示嵌入维度。


# 开集检测（OVD）








# 视觉框架

使用Pytorch构建一个新算法时，通常包含如下几步：
- 构建数据集：新建一个类，并继承Dataset类，重写__getitem__()方法实现数据和标签的加载和遍历功能，并以pipeline的方式定义数据预处理流程
- 构建数据加载器：传入相应的参数实例化DataLoader
- 构建模型：新建一个类，并继承Module类，重写forward()函数定义模型的前向过程
- 定义损失函数和优化器：根据算法选择合适和损失函数和优化器
- 训练和验证：循环从DataLoader中获取数据和标签，送入网络模型，计算loss，根据反传的梯度使用优化器进行迭代优化
- 其他操作：在主调函数里可以任意穿插训练Tricks、日志打印、检查点保存等操作

## Detectron2
使用 Detectron2 如何构造一个模型：
- 准备数据集：注册COCO格式数据集或者使用自定义结构数据集，注册 DatasetCatalog 和 MetadataCatalog，告诉模型如何提取数据
- 加载 Dataloader：dataloader包含一个mapper，负责将输入的图片格式经过数据增强变为模型可以直接拿去 forward 的格式。可以使用 DefaultMapper或者自己实现 mapper。
- 创建模型：配置好 config 后，build_model(cfg) 直接根据 config 中定义的各个组件拼接模型。各个组件 Detectron2 也提供了 Registry 机制，可以直接注册自己写的组件，之后在 config 中快速调用。
- 训练模型：可以直接使用 DefaultTrainer，继承自 SimpleTrainer，包含了训练常用的基础参数和操作。如果不能满足需求直接继承 DefaultTrainer 重写方法即可。
- 评测模型：可以直接使用 DatasetEvaluator 对模型性能进行评测。如果使用自定义数据集，可以直接继承 DatasetEvaluator 重写方法。
- 单张推理：可以直接使用 DefaultPredictor，如果不能满足需求，也可以继承重写方法。


## MMDetection

使用 MMDet 构建一个新算法时，通常包含如下几步：
- 注册数据集：继承CustomDataset类的方式构建自己的数据集时，需要重写load_annotations()和get_ann_info()函数，定义数据和标签的加载及遍历方式。完成数据集类的定义后，还需要使用DATASETS.register_module()进行模块注册。
- 注册模型：模型构建的方式和Pytorch类似，都是新建一个Module的子类然后重写forward()函数。唯一的区别在于MMDetection中需要继承BaseModule而不是Module，BaseModule是Module的子类，MMLab中的任何模型都必须继承此类。另外，MMDetection将一个完整的模型拆分为backbone、neck和head三部分进行管理，所以需要按照这种方式，将算法模型拆解成3个类，分别使用BACKBONES.register_module()、NECKS.register_module()和HEADS.register_module()完成模块注册。
- 构建配置文件：配置文件用于配置算法各个组件的运行参数，大体上可以包含四个部分：datasets、models、schedules和runtime。完成相应模块的定义和注册后，在配置文件中配置好相应的运行参数，然后MMDetection就会通过Registry类读取并解析配置文件，完成模块的实例化。另外，配置文件可以通过_base_字段实现继承功能，以提高代码复用率。
- 训练和验证：在完成各模块的代码实现、模块的注册、配置文件的编写后，就可以使用./tools/train.py和./tools/test.py对模型进行训练和验证，不需要用户编写额外的代码。

**注册机制**

注册机制就是维护几张查询表，key是模块的名称，value是模块的句柄，每张查询表都管理一批功能相似的不同模块。我们每新建一个模块，都要根据模块实现的功能将对应的key-value查询对保存到对应的查询表中，这个保存的过程就称为“注册”。当我们想要调用某个模块时，只需要根据模块名称从查询表中找到对应的模块句柄，然后就能完成模块初始化或方法调用等操作。MMCV通过Registry类来实现字符串(key)到类(value)的映射。

**Hook机制**

Hook可以理解为一种触发器，可以在程序预定义的位置执行预定义的函数。MMCV根据算法的生命周期预定义了6个可以插入自定义函数的位点，可以在每个位点自由地插入任意数量的函数操作。这6个位置基本涵盖了自定义操作可能出现的位置，MMCV已经实现了部分常用Hook，其中默认Hook不需要用户自行注册，通过配置文件配置对应的参数即可；定制Hook则需要用户在配置文件中手动配置custom_hooks字段进行注册。

定义好一个Hook(并注册到HOOKS注册器中)之后，还需要注册到Runner中才能使用，前后一共进行两次注册。第一次注册到HOOKS是为了程序能够根据Hook名称找到对应的模块，第二次注册到Runner中是为了程序执行到预定义位置时能够调用对应的函数。

<div align=center>
 <img src="imgs/mmdet位点.png" width="400px">
</div>






# 扩散模型

## Janus

Janus系列的核心创新点在于通过视觉编码解耦同时优化多模态理解（如视觉问答）和生成（如图像描述生成）任务。传统的统一模型使用单一视觉编码器处理理解和生成任务。然而，这两种任务对视觉信息的需求不同：理解任务（如VQA）需要高层语义特征，如物体类别、关系;生成任务（如图像描述）依赖细粒度细节，如局部纹理、细节。因此Janus虽然使用同一个transformer结构，但是将理解和生成任务的使用的编码器解耦。在理解任务上采用语义导向的编码器（如SigLIP）提取全局语义特征，在生成任务上使用细粒度编码器（如VQ-GAN），保留局部细节信息。

**网络结构**

1)编码:三种任务使用各自的编码器，将原始输入转化为特征序列

- 纯文本理解:使用LLM内置的文本分词器,文本 → 离散ID → LLM词嵌入特征;
- 多模态理解:图像使用SigLIP编码器提取高维语义特征,图像 → SigLIP 2D特征网格 → 展平为1D序列 → Adaptor映射（线性映射至LLM输入空间）
- 视觉生成:图像使用和LlamaGen类似的VQ-GAN，转换为离散ID,图像 → VQ离散ID序列 → 展平为1D序列 → Adaptor映射（将ID对应的Codebook嵌入映射至LLM输入空间）

2)特征融合与统一处理:不同任务的特征序列（文本/图像）在输入维度对齐后，按任务需求拼接为统一的多模态特征序列。拼接后的序列输入LLM Transformer，无需针对多模态设计特殊注意力机制，仅依赖标准causal attention mask。

3)预测头:多模态理解等输出文本的任务复用LLM内置的文本预测头（如语言模型Head），视觉生成任务使用随机初始化的图像预测头，从LLM输出解码生成VQ-ID序列 → 通过VQ解码器重建图像。

**训练策略**

1)Stage I: 训练 Adaptor与图像头：将视觉和文本在embedding space上建立联系。冻结视觉编码器（SigLIP/VQ分词器）、LLM主体参数，训练Adaptor和视觉生成head。

2)Stage II: 统一预训练：同时学习多模态理解和生成。unfreeze LLM主体参数和head，训练除了encoder的所有部分。使用文本数据、多模态理解数据和生成数据进行训练。在视频生成任务上分为两步，第一步（前66.67%的训练步数）使用ImageNet-1k数据，以类别作为prompt，让模型学习像素级依赖关系（如局部纹理连续性）。第二步加入通用的文本-图像数据，提升复杂语义对齐能力（如“抽象概念→细节生成”）。

3)Stage III: 监督微调：提升follow指令能力和对话能力。unfreeze 理解相关的encoder，继续冻结生成编码器，防止生成质量波动。仅监督答案部分（如掩码用户提问），强制模型关注输出质量。多任务混合，避免为特定任务单独微调，维持统一模型的多功能性。



**DeepSeek Janus Pro**

多数方法使用相同的视觉编码器处理多模态理解和生成任务的输入，但这两个任务所需的表示不同，导致多模态理解性能欠佳。Janus 模型提出解耦视觉编码，缓解了多模态理解和生成任务之间的冲突，在两个任务上都表现出色。但由于训练数据量有限和模型容量较小，存在一些缺陷，如在短提示图像生成上表现欠佳，文本到图像的生成质量不稳定。Janus Pro 从训练策略、数据和模型大小三个维度对 Janus 进行改进。

- 训练策略：延长第一阶段训练步骤、调整第二阶段训练数据使用方式，以及改变第三阶段不同类型数据集的数据比例，提升了训练效率和模型性能。
- 数据：在多模态理解和视觉生成方面分别增加大量样本，增强了模型处理多样任务的能力，提高了文本到图像生成的稳定性和美学质量。
- 模型大小：模型规模扩展到 70 亿参数，验证了该方法的强扩展性，在多模态理解和视觉生成任务中损失收敛速度更快。

Janus-Pro 的架构与 Janus 相同，核心设计原则是解耦多模态理解和生成的视觉编码。运用独立的编码方法将原始输入转换为特征，再由统一的自回归变压器进行处理。多模态理解时，使用 SigLIP 编码器从图像中提取高维语义特征，将其从二维网格展平为一维序列，通过理解适配器映射到LLM的输入空间。视觉生成任务时，使用 VQ 分词器将图像转换为离散 ID，展平为一维后，利用生成适配器将每个 ID 对应的码本嵌入映射到 LLM 的输入空间，连接这些特征序列形成多模态特征序列，输入 LLM 处理。除 LLM 内置的预测头，视觉生成任务还使用随机初始化的预测头进行图像预测，整个模型遵循自回归框架。


## Nvidia Sana
Sana 是一个高效的文生图的框架，能以极快的速度合成高分辨率、高质量的图像，并具有很强的文本图像对齐能力。

核心设计：
- **深压缩自动编码器**：与只能将图像压缩 8 倍的传统自动编码器 AE 不同，Sana 训练的 DC-AE 可将图像压缩 32 倍，从而有效减少潜在标记的数量。
- **linear DiT**：用线性注意力取代了 DiT 中的自注意力，计算复杂度从 O(N^2) 降低到 O(N)，在高分辨率生成中提高了计算效率且不影响性能。
- **纯解码器文本编码器**：使用现代的纯解码器小型大型语言模型(LLM)如 Gemma 作为文本编码器，与传统的T5相比，仅解码器的 LLM 具有更强的文本理解和推理能力。
- **高效训练和采样**：提出多标题自动标记管道，为每个图像使用多个视觉语言模型（VLM）生成重新标题，然后基于剪辑分数（clip score）的采样策略，根据概率选择高质量的标题，提高了训练收敛性和文本 - 图像对齐。提出 Flow-DPM-Solver，减少了推理采样步骤，同时取得了更好的结果。

**深压缩自动编码器**

早期潜在扩散模型LDM（如Stable Diffusion）使用预训练自编码器将图像压缩至潜在空间，下采样因子（F）通常为8，扩散模型（如DiT）需处理大量潜在空间token，导致大量冗余计算。传统方法（如AE-F8C4P2，F是下采样因子，C是潜在通道数，P是patch size）压缩率有限（8倍），而尝试更高压缩率（如AE-F32C64）会导致重建质量显著下降。

DC-AE 将下采样因子从F=8提升至F=32，图像尺寸缩小32倍，潜在通道数（C）设为32（而非传统方法的4或16），平衡信息保留与压缩效率。采用P=1（而非传统P=2），避免分块操作对扩散模型的干扰，确保模型专注于去噪。通过优化潜在通道分布和训练策略，尽管压缩率提升至32倍，与传统8倍压缩模型差距极小。实验表明，自编码器的微小质量差异不会成为扩散模型能力的瓶颈，DiT仍能有效恢复图像内容。

**LDM**

通过在潜在表示空间上进行 diffusion 过程的方法，从而能够大大减少计算复杂度并达到较好的效果。
感知压缩模型：给定一个RGB空间内的图像 x ，编码器把 x 编成潜空间的 z，解码器从潜空间把 z 解码回 x'。（x->z 是一个非线性降维过程）
潜在扩散模型引入预训练的感知压缩模型，使模型能够在潜在表示空间中学习。
条件机制本质在于通过交叉注意机制增强其底层 UNet 主干，将 DM 转变为更灵活的条件图像生成器，让基于 attention 的模型学习多种输入模态更有效。
LDM 训练过程分两步：第一步，训练一个VAE，得到 x 到 zt 的编码器 Encoder 和还原回 x' 的解码器 Decoder；第二步，训练一个扩散模型 LDM，学习一个噪声到 zt 的生成过程。其中 LDM 的架构是个Unet（如果包含条件输入的话，则条件信息的编码器与LDM一起训练）。推理过程分为无条件信息和有条件信息两种情况：没有条件信息时，从高斯噪声采样，经过LDM模型，得到潜空间图像 zt，zt 经过 Decoder 模型还原到原图；有条件信息时，从高斯噪声采样，条件信息经过条件处理的编码器得到的输出与初始高斯噪声以及u-net进行耦合（concat，attention），经过 LDM 得到潜在空间图像 zt，zt 经过 Decoder 模型还原到原图。

**linear DiT**

DiT 使用的自注意力的计算复杂度为O(N2)，在处理高分辨率图像时计算效率较低，开销较大。linear DiT 完全用线性注意力替换原始的自注意力（将传统的 softmax 注意替换为 ReLU 线性注意），线性注意力的收敛速度较慢，为提高训练效率，使用 MixFFN 来替换原始的 MLP-FFN，使用 Triton 来融合线性注意块的前向和后向传递的核，以加快训练和推理速度，最终在不影响性能的情况下在高分辨率生成中实现了更高的计算效率。Mix-FFN 由倒置残差块、3×3 深度卷积和门控线性单元 (GLU) 组成。深度卷积增强了模型捕获局部信息的能力，弥补了ReLU线性注意的较弱局部信息捕获能力。

Triton则通过提供领域特定的语言和编译器，面向底层的GPU kernel开发和编译优化问题，使得开发者能够以更高的抽象层次编写高效的GPU Kernel，从而提升性能。

**DiT**

Diffusion Transformers (DiTs)：通过使用 LDM 框架，Diffusion Model 中的 U-Net 架构可以被 Transformer 替换。

DiT 首先将图片 Patchify，并经过 Linear Embedding，最终变为 T 个 d 维的 tokens。在 Patchify 之后，将标准的基于 ViT(Vision Transformer) 频率的位置编码 (sine-cosine 版本) 应用到所有的输入 tokens 上面。输入的 tokens 开始进入一系列 Transformer Block 中。除了噪声图像输入之外，Diffusion Model 有时会处理额外的条件信息，比如噪声时间步长 t, 类标签 c, 自然语言。
设计 4 种不同类型的 Transformer Block 以不同的方式处理条件输入，这些设计都对标准 ViT Block 进行了微小的修改。

**纯解码器文本编码器**

仅解码器的 llm 可以通过使用思维链 (CoT) 和上下文学习 (ICL)来跟踪复杂的人类指令。采用 Gemma-2 作为文本编码器，这个小型llm可以与大型llm的性能相媲美，同时非常高效。

**思维链 (CoT)**

通过让大模型逐步参与将一个复杂问题分解为一步一步的子问题并依次进行求解的过程可以显著提升大模型的性能。一系列推理的中间步骤即为思维链。一个完整的包含 CoT 的 Prompt 往往由指令（Instruction），逻辑依据（Rationale），示例（Exemplars）三部分组成。指令用于描述问题并且告知大模型的输出格式，逻辑依据即指 CoT 的中间推理过程，可以包含问题的解决方案、中间推理步骤以及与问题相关的任何外部知识，而示例则指以少样本的方式为大模型提供输入输出对的基本格式，每一个示例都包含：问题，推理过程与答案。

作用：显式输出中间逐步的推理步骤能够增强大模型的算数、常识和推理的性能，并方便使用者了解模型的思考过程，提高了大模型推理的可解释性。

适用场景：任务需要复杂推理；参数量的增加无法使得模型性能显著提升；不太适用于简单任务及参数量较小的模型。

**上下文学习 (ICL)**

在假设空间中，给定一个训练集S，模型将其映射为任务向量θ(S)，该向量表示为训练集S中映射/规则的描述。这种能力即为 ICL。

**GPT系列模型**

与encoder-decoder架构相比，decoder-only架构相对简单，减少了模型复杂性和开发难度。对于需要强大文本生成能力而不需要深层次文本理解能力的应用，decoder-only模型是理想选择。GPT系列模型通过自回归训练方式，即根据已生成的文本序列预测下一个词，这种训练方式使得模型在文本生成任务中表现出色。

GPT系列与其他NLP架构的比较：

- Encoder-only架构：单向架构，仅包含编码器部分。主要适用于不需要生成序列的任务，只需要对输入进行编码和处理的单向任务场景，如文本分类、情感分析等。如 BERT、RoBERT 和 ALBERT 等。核心思想是利用神经网络对输入文本进行编码，提取其特征和语义信息，并将编码结果传递给后续的处理模块。优点是能够更好地理解输入文本的语义和上下文信息，从而提高文本分类和情感分析等任务的准确性。缺点是它无法直接生成文本输出，因此在需要生成文本的任务中不太适用。
- Encoder-decoder架构：同时包含编码器和解码器部分。通常用于序列到序列（Seq2Seq）任务，如机器翻译、对话生成等。如 Google 的 T5、华为的盘古NLP大模型等。核心思想是利用编码器对输入序列进行编码，提取其特征和语义信息，并将编码结果传递给解码器，解码器根据编码结果生成相应的输出序列。优点是能够更好地处理输入序列和输出序列之间的关系，从而提高机器翻译和对话生成等任务的准确性；缺点是模型复杂度较高，训练时间和计算资源消耗较大。
- Decoder-Only架构：生成式架构，仅包含解码器部分。一个重要特点是可以进行无监督预训练。如 GPT 系列、OPT等。在预训练阶段，模型通过大量的无标注数据学习语言的统计模式和语义信息。它更多关注于从已有的信息（开头）扩展出新的内容，其缺点是需要大量的训练数据来提高生成文本的质量和多样性。

**高效训练和采样**

基于DPM-Solver++，提出 Flow-DPM-Solver，减少了推理采样步骤，同时取得了更好的结果。关键调整包括用1−σt替换比例因子αt，其中σt保持不变，但时间步长在[0,1]范围内重新定义，而不是[1,1000]，时间步长偏移用于实现较低的信噪比。


## 先验概念
- 马尔可夫链：状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。
- 极大似然估计：对于给定的观测数据x，从所有的参数θ1,θ2,θ3...中找出能最大概率生成观测数据的参数θ*作为估计结果。
- KL 散度：不对称统计距离度量，用于衡量一个概率分布 P 与另外一个概率分布 Q 的差异程度。

**生成模型**

- GAN：由一个生成器（generator）和判别器（discriminator）组成，生成器的任务是生成尽可能接近真实数据的假数据，而判别器的任务是区分输入数据是真实数据还是生成器生成的假数据。二者通过相互竞争与对抗，共同进化，最终生成器能够生成非常接近真实数据的样本。
- VAE：变分自编码器,基于概率图模型的生成模型，通过学习数据的潜在分布来生成新样本。它假设隐变量服从某种先验分布（如标准正态分布），并通过编码器将输入数据映射到隐变量的后验分布，再通过解码器将隐变量还原成生成样本。
- Flow：通过一系列可逆的变换，将简单分布（如均匀分布或正态分布）转换为复杂的数据分布。在训练阶段，通过最小化潜在空间中的样本与真实数据之间的损失函数来学习可逆变换的参数。
- Diffusion：将数据生成过程看作一个马尔可夫链。从目标数据开始，每一步都向随机噪声靠近，直到达到纯噪声状态。然后，通过反向过程，从纯噪声逐渐恢复到目标数据。

## Questions

**Question： 扩散模型常见采样方式?**

在采样过程中，根据是否添加额外的噪声，可以将扩散模型采样器归纳为两种：扩散随机微分方程模型（Diffusion SDE）与扩散常微分方程（Diffusion ODE）。两种模型的训练目标函数都一样，通过最小化与噪声的均方误差来训练一个“噪声预测网络”。
   
- DDPM：SDE 的一阶离散化。基于马尔可夫链的前向（加噪）和反向（去噪）过程。反向过程通过训练神经网络逐步预测噪声，从纯噪声中恢复数据。
- DDIM：ODE 的一阶离散化。通过非马尔可夫链的重新参数化，打破 DDPM 的严格马尔可夫性，允许跳步采样。速度显著提升，且与 DDPM 共享模型权重。

这些一阶的离散化方法收敛速度极慢，扩散模型的采样通常需要 100 到 1000 次串行计算才可以得到高质量的图片。为了加速扩散模型的采样，通过对 Diffusion ODE 使用高阶求解器来进行加速，

- DPM：结合高阶泰勒展开和自适应步长策略，实现低步数的高质量生成。计算效率高，支持随机性（随机微分方程SDE）和确定性（常微分方程ODE）两种模式。
- DPM-Solver：将扩散模型的采样过程重新定义为求解常微分方程(ODE)，并设计了一个高阶 ODE 求解器，去尽量避免线性部分的误差。DDIM 本质上是 DPM-Solver 的一阶形式。

**Question： 扩散模型能否使用其他噪声的加噪方式?**
  
  扩散模型的核心是定义前向加噪过程（将数据逐步破坏为噪声）和反向去噪过程（从噪声恢复数据）。噪声类型需满足以下条件：1）可逆性：前向过程的每个步骤需能被反向过程近似；2）可解析的分布形式：需能推导出加噪后的数据分布和反向条件分布 ；3）训练损失可计算：例如，基于KL散度或得分匹配的目标函数需可优化。
常见替代噪声类型：伯努利噪声，在二值化数据（如文本的token序列或黑白图像）中，每一步以概率βt将像素/比特随机翻转（0→1或1→0）。反向过程需建模离散状态转移，无法直接使用连续梯度下降，常需引入Gumbel-Softmax(重参数化技巧)等技巧。案例：Bit Diffusion模型用于生成离散文本和分子结构。

**Question： Diffusion加速方法?**

   采样速度提升：改进采样策略或设计高效求解器，显著降低生成所需的迭代次数，如快速采样器（DDIM、DPM系列）等;
   模型架构优化：改进网络结构或降低计算复杂度提升推理速度，如轻量化U-Net设计、知识蒸馏等；
   数学方法改进：优化扩散过程的数学建模实现加速，如微分方程求解器优化（利用更高阶的数值方法或自适应策略，减少生成高质量样本所需的迭代步数）等。

**Question： DDPM和DDIM的关系?**

   差异：
   - 前向过程的差异：DDPM的前向过程是马尔可夫链，每一步添加高斯噪声，βt是预定义的噪声调度参数。DDIM引入非马尔可夫前向过程，通过重新参数化允许更灵活的噪声路径，μt和σt是隐式定义的参数，允许跳过中间步骤。
   - 反向过程的优化：DDPM反向过程严格依赖马尔可夫链，逐步去噪，需迭代计算所有中间步骤。DDIM通过隐式条件分布直接建模x0与xt的关系，允许跳步采样。
   
   联系：共享模型权重：DDIM可以直接复用DDPM的预训练模型，两者的训练目标一致（均通过预测噪声优化），仅采样策略不同。
   
**Question： GAN和Diffusion的区别?**

| 特性         | GAN                                           | Diffusion Model                                      |
|--------------|-----------------------------------------------|------------------------------------------------------|
| 基本思想      | 对抗训练：生成器（G）和判别器（D）通过博弈提升生成能力| 扩散过程：通过逐步加噪和去噪学习数据分布            |
| 生成过程      | 一步生成：直接输出样本（如从噪声向量到图像）| 多步迭代生成：逐步去噪（如从纯噪声恢复图像）|
| 训练目的      | 对抗损失：生成器欺骗判别器，判别器识别真假。|噪声预测损失：通过均方误差（MSE）优化模型对噪声的预测。|
| 训练过程      | 不稳定，易出现模式崩溃，但单步生成训练效率高|损失函数平滑，逐步优化，不易崩溃，模拟多步扩散过程，训练效率低|

**Question： 为什么DDPM加噪声的幅度是不一致的?**

加噪声的幅度不一致是由其扩散过程的数学设计和训练目标共同决定的。
- 1）扩散过程需要平滑过渡：通过逐步增大噪声幅度，扩散过程可以确保数据分布从原始分布平滑过渡到标准高斯分布。若所有噪声幅度都相同，可能导致过渡不平稳（如某些中间状态出现尖锐分布）。
- 2）训练目标的适配性：实际中需要覆盖从低噪声（接近原始数据）到高噪声（接近纯噪声）的所有情况。不一致的噪声幅度迫使模型在不同时间步学习不同程度的去噪操作。早期（低噪声）时，模型需修复细节（如纹理、边缘）；后期（高噪声）时：模型需捕捉整体结构（如物体形状）。
- 3）生成质量的优化：在生成阶段（反向扩散过程），若所有噪声幅度一致，可能导致模型在去噪时陷入局部最优（如生成模糊结果），且模型可能倾向于生成相似样本（模式坍塌）。动态噪声幅度鼓励多样性。

**Question： 训练Stable Diffusion时为什么要使用offset Noise?**

Offset Noise是指在标准高斯噪声的基础上，引入一个可学习的偏移量（通常通过调整噪声的均值或方差），从而改变噪声的分布特性。

$$
\epsilon_{\mathrm{offset}} = \epsilon + \delta \quad \text{或} \quad \epsilon_{\mathrm{offset}} = \epsilon \cdot \gamma + \delta
$$

$\epsilon \sim \mathcal{N}(0, I)$是标准高斯噪声；$\delta$是偏移量（可学习参数）；$\gamma$是缩放因子（可学习参数）。

使用Offset Noise的核心原因：
- 1）缓解训练中的过平滑问题：在扩散模型的去噪过程中，模型可能倾向于生成过于平滑的图像（丢失细节），尤其是当噪声强度较高时。通过Offset Noise调整噪声分布，迫使模型学习更复杂的噪声模式，从而保留高频细节（如纹理、边缘）。
- 2）增强模型对噪声分布的适应性：传统扩散模型假设噪声严格服从高斯分布，但真实场景中可能存在非对称或非高斯的噪声（如传感器噪声、压缩伪影）。Offset Noise通过引入偏移量或缩放因子，使噪声分布更灵活，模型能适应更广泛的数据分布。
- 3）改善训练稳定性：Offset Noise可调节不同时间步的噪声强度，避免某些时间步的梯度爆炸或消失（尤其在噪声强度剧烈变化时）。
- 4）提升生成多样性：Offset Noise增加了噪声的随机性组合，避免生成结果过于模式化（如人脸生成中的重复特征）。

**Question： 推演DDPM公式**

1）前向扩散过程

$$\mathbf{x}_t = \sqrt{\bar{\alpha}}_t \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}}_t \mathbf{\epsilon}, \quad \mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$

2）反向去噪过程

![image](imgs/反向去噪过程.png)

3）目标函数(ELBO)

![image](imgs/ELBO.png)

# 注意力
## 1. 背景知识

**1.1 自回归模型**

自回归（Autoregressive）模型是一种生成模型，遵循因果原则（当前单词只受到其前面单词的影响），利用一个变量的历史值来预测其未来的值，在每个时间步，模型根据之前生成的元素预测当前元素的概率分布。
自回归模式弊端：容易累积错误，导致训练效果不佳；难以并行化的方式开展训练、提升效率。

**1.2 编码器-解码器**

对于输入输出都是变长的序列，可以使用一个定长的状态机来作为输入和输出之间的桥梁。编码器-解码器架构：前半部分的RNN只有输入，后半部分的RNN只有输出（上一轮的输出会当作下一轮的输入以补充信息），两个部分通过一个隐状态（hidden state）来传递信息。优化目标函数为真值与预测值的距离度量函数，通常用MSE（均方方差）。

编码器把输入句子的所有语义信息压缩成一个固定长度的中间语义向量（也称为上下文向量或隐向量），该向量包含了可供计算与学习的、代表句子语言特点和含义的特征信息，是输入的浓缩摘要。解码器会把这个中间语义上下文向量解码成输出句子，即解码器将编码器学习到的特征信息再转化为相应的句子。
序列建模的核心就是研究如何把长序列的上下文压缩到一个较小的状态中。

输入层神经元的个数 n 大于隐层神经元个数 m 时，相当于把数据从 n 维降到了 m 维；然后利用这 m 维的特征向量，进行重构原始的数据。区别于 PCA 求解特征向量的线性降维，自编码是一种非线性降维。

**1.3 技术挑战**

CNN：卷积感受视野是局部的，学习空间数据中的局部依赖关系。
RNN：时序结构，后面的时刻天然就依赖于前面时刻的输出。
- 对齐问题：CNN和RNN都难以在源序列和目标序列之间做到完美对齐。
- 隐状态长度固定：RNN的隐向量大小固定，所以推理效果受限于信息压缩的能力，导致信息遗失。
- 关系距离问题：都存在。序列中两个词之间的关系距离不同，当词之间距离过长时，两个方案都难以确定词之间的依赖关系。使得当面临冗长且信息密集的输入序列时，模型在整个解码过程中保持相关性的能力可能会减弱。



## 2. 注意力机制

**2.1 普通注意力**

注意力机制确保每个解码步骤都由最相关的上下文片段提供信息，解决了长距离依赖问题，但其计算速度慢、存储占用高。
本质：上下文决定一切；核心思想：为输入的不同部分分配不同的权重，以提取关键信息，让模型判断更精准，更加节省算力和存储。
query、key、value 代表相关向量，用**Q**（查询矩阵）、**K**（键矩阵）、**V**（值矩阵）代表相关向量构成的矩阵，名义上的称呼代表使命，本质都是输入矩阵。
计算流程：
- ① 是输入（两个输入），从输入生成的特征向量F通过三个权值矩阵生成**Q**、**K**和**V**。
- ② 使用矩阵 **K** 和查询向量 **q** 作为输入，通过相似度计算函数来计算注意力得分向量 **e** 。**q** 表示对信息的请求，**el** 表示矩阵 K 的第 **l** 列对于 **q** 的重要性。
- ③ 通过对齐层（比如softmax函数）进一步处理注意力分数，进而得到注意力权重a。
- ④ 利用注意力权重 **a** 和矩阵 **V** 进行计算，得到上下文向量**c**。

1）**计算query、key、value向量**。词向量（对输入序列添加位置编码）通过三个权值矩阵 W^Q、W^K、W^V转变为**Q**、**K**和**V** ；
2）**计算注意力得分**。**Q**和**K**点积得到，点积注意力计算起来更快更简单；
3）**softmax归一化**。通过softmax计算，将每个单词之间的得分向量转换成[0,1]之间的概率分布，同时更加凸显单词之间的关系；
4）**将每个value向量乘以注意力分数**。留下想要关注的局部特征，并把不相关的特征丢掉；

<div align=center>
 <img src="imgs/attention.png" width="600px">
</div>

掩码注意力不同于普通注意力，在 Softmax 之前，先使用 Mask 矩阵遮挡住每一个单词之后的信息，这意味着只关注这个词之前的所有词的状态。

交叉注意力（Transformer解码器、跨模态）关注不同序列之间的注意力，自注意力机制（BERT、ViT）用于捕捉同一序列内部元素之间的依赖关系。

多头注意力（所有Transformer模块）通过并行多个独立的注意力头（原来向量等分，输出进行拼接），从不同子空间学习多样化的特征表示，增强模型表达能力。

**2.2 线性注意力**

   注意力机制通过计算查询向量与所有键向量的相似度，获得注意力权重，再用这些权重对相应的值向量进行加权组合。在此过程中使用softmax函数的目的是将原始相似度分数转换为概率分布，这在本质上类似于k近邻机制，即相关性更高的键值对获得更大的权重。标准注意力机制需要对NxN维度的矩阵执行softmax运算，这导致计算复杂度随序列长度呈二次方增长。虽然这种计算复杂度对于较短序列是可接受的，但在处理长度达到100k以上的序列时，计算效率会显著降低。

**将softmax指数函数重写为特征映射函数φ(x)=elu(x) + 1的点积形式的核函数**，**并利用矩阵乘法的结合律，将注意力计算重构为线性形式**。这种重构方法消除了计算完整N×N注意力矩阵的需求，将复杂度降低至O(Nd²)，其中d表示嵌入维度。

   局限：由于状态矩阵的维度限制为d × d，其信息存储容量存在上限。比如：如果原始上下文需要存储20d²的信息量，在压缩过程中将不可避免地损失19d²的信息。**通过维持固定维度的状态矩阵获得计算效率的同时，也限制了上下文信息的保存能力。**

**2.3 门控线性注意力**

   在使用固定维度状态矩阵优化计算效率的过程中，信息损失是不可避免的，但可以通过一种选择性信息过滤机制（门控函数），智能地选择需要保留的信息来最小化信息损失的影响。门控函数仅依赖于当前token和可学习参数，而不需要考虑完整的序列历史。由于各个token的门控计算相互独立，这种设计实现了训练过程的高效并行化，使得序列中所有token的门控运算能够同时进行。

## 3. Transformer

Transformer结构：一个编码器（encoder）模块和一个解码器（decoder）模块组成。编码器模块是n个encoder组件堆在一起，同样解码器模块也是n个decoder组件堆在一起 (n是一个可调参数)。n个编码器组件的结构是相同的，但是它们之间的权重是不共享的。
编码器：每个编码器组件都可以分为2个子层。编码器的输入首先会进入一个自注意力层（Self-Attention），自注意力层的输出会传递给一个前馈神经网络(Feed Forward Neural Network)，每个编码器组件都是在相同的位置使用结构相同的前馈神经网络。
解码器：解码器组件也含有前面编码器中提到的两个层，区别在于这两个层之间还夹了一个注意力层，多出来的这个自注意力层的作用是让解码器能够注意到输入句子中相关的部分（和seq2seq中的attention一样的作用）。

**3.1 Transformer输入**

单词的输入表示 x 由Input Embeddings(单词向量) 和Poditional Encoding(位置编码) 相加得到。位置编码是遵循某些特定模式的，位置编码向量和单词embedding的维度是一样的。

为什么是将positional encoding与词向量相加，而不是拼接呢？拼接相加都可以，只是本身词向量的维度512维就已经蛮大了，再拼接一个512维的位置向量，变成1024维，这样训练起来会相对慢一些，影响效率。两者的效果是差不多地，既然效果差不多当然是选择学习习难度较小的相加了。

单词的 Embedding 有很多种方式可以获取，例如可以采用 Word2Vec、Glove， one-hot 等算法预训练得到，也可以在 Transformer 中训练得到。

Transformer 中除了单词的 Embedding，还需要使用位置Embedding 表示单词出现在句子中的位置。因为 Transformer 不采用 RNN 的结构，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要。所以 Transformer 中使用位置 Embedding 保存单词在序列中的相对或绝对位置。Transformer中采用的是基于正弦函数和余弦函数的固定位置编码；BERT中的位置编码是通过训练得到的。

**3.2 Encoder-Decoder**

左侧为 Encoder block，右侧为 Decoder block。Multi-Head Attention 由多个 Self-Attention组成， Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add & Norm 层，Add 表示残差连接 (Residual Connection) 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。

Encoder 中包括N个Encoder block, 每个Encoder block的结构相同，但是权重不共享。每个Encoder block主要由Multi-Head Attention、Add&Norm、Feed Forward 三种结构组成。

解码器有两种类型，**自回归的Decoder（AT）和非自回归的解码器（NAT）**。Decoder每次选择softmax后概率最大的元素作为输出，每次预测时，需要将前一时刻的预测输出作为输入。第一次预测时，输入的是START起始符。因此在词汇表中加入了END 作为终止符，自回归的解码器（AT）, 当预测输出END时，AT就会停止工作。对于非自回归的解码器（NAT）而言，有两种方法：a) 额外采用一个预测器来预测输出的长度。b) 输出一个很长的序列，但忽略END后的输出。NAT的优点：可以并行计算，且生成更稳定，但是NAT一般没有AT的效果好，因此在Transformer中我们用的是AT模型。



<div align=center>
 <img src="imgs/Transformer.jpeg" width="400px">
</div>








参考：

 （mamba详解）https://segmentfault.com/a/1190000044635654

（注意力机制）https：//www.cnblogs.com/rossiXYZ/p/18705809

（注意力机制和Transformer）https://blog.csdn.net/zyw2002/article/details/128788680

（扩散模型）https：//tanxy.club/Diffusion-Model

（Janus-pro）https://blog.csdn.net/m0_65555479/article/details/145413860

（DS三大模型）https://blog.csdn.net/determinedmannn/article/details/145386486

（Sana）https://blog.csdn.net/xiaobing259/article/details/143432789

（Transformers）https://sanjayasubedi.com.np/series/transformers/

